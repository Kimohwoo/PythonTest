{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 배열(array): 데이터를 효율적으로 저장하고 다루기 위해 사용.\\\n",
    " NumPy를 사용하여 배열을 생성하고, 배열 간의 연산이나 슬라이싱과 같은 다양한 작업을 수행할 수 있음.\n",
    "\n",
    "- 텐서(Tensor): 주로 머신러닝과 딥러닝에서 데이터를 다루기 위해 사용.\\\n",
    " 딥러닝 모델은 주로 텐서를 입력으로 받고, 텐서를 출력으로 내보냄.\\\n",
    "  딥러닝 라이브러리인 파이토치와 텐서플로는 텐서를 생성하고, 뉴럴 네트워크의 학습과 예측 과정에서 텐서를 다루는 기능을 제공."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1,2], [3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.FloatTensor([[1,2,3], [4,5,6]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor([[1,2,],[3,4]]))\n",
    "# print(torch.tensor([[1,2,],[3,4]]), device=\"cuda:0\") #cuda tenser만드는것\n",
    "print(torch.tensor([[1,2,],[3,4]], dtype=torch.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "ft=torch.FloatTensor([[1,2,],[3,4]])\n",
    "lt=torch.LongTensor([[1,2],[3,4]])\n",
    "bt=torch.ByteTensor([[1,2],[3,4]]) #8bit로 작성되었단 결과가 나옴\n",
    "print(ft)\n",
    "print(lt)\n",
    "print(bt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]] <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nparray\n",
    "import numpy as np\n",
    "\n",
    "x=np.arange(0,9).reshape(3,3)\n",
    "print(x, type(x))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "#array->torch로 변환\n",
    "tx=torch.from_numpy(x)\n",
    "print(tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#torch->nparray\n",
    "nx=tx.numpy()\n",
    "print(nx, type(nx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.],\n",
      "        [6., 7., 8.]])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "tx #<- long형인데  float형으로, float형인데 long형으로\n",
    "ft=tx.float()\n",
    "print(ft)\n",
    "lt= ft.long()\n",
    "print(lt)\n",
    "bt=ft.byte()\n",
    "print(bt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  2],\n",
       "        [ 3,  4],\n",
       "        [ 5,  6]],\n",
       "\n",
       "       [[ 7,  8],\n",
       "        [ 9, 10],\n",
       "        [11, 12]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na=np.arange(1,13).reshape(2,3,2) #(z, y, x축)\n",
    "na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=torch.from_numpy(na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 2])\n",
      "torch.Size([2, 3, 2])\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(t.size())  # 텐서의 크기를 출력합니다.\n",
    "\n",
    "print(t.shape)  # 텐서의 모양(shape)을 튜플 형태로 출력합니다.\n",
    "\n",
    "print(t.size(0))  # 텐서의 첫 번째 차원의 크기를 출력합니다.\n",
    "\n",
    "print(t.shape[2])  # 텐서의 세 번째 차원의 크기를 출력합니다.\n",
    "\n",
    "print(t.dim())  # 텐서의 차원 수를 출력합니다.\n",
    "\n",
    "print(len(t.shape))  # 텐서의 차원 수를 출력합니다. t.dim()과 동일한 결과입니다.\n",
    "\n",
    "print(t.size(-1))  # 텐서의 마지막 차원의 크기를 출력합니다.\n",
    "\n",
    "print(t.shape[-1])  # 텐서의 마지막 차원의 크기를 출력합니다. t.size(-1)과 동일한 결과입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[ 1.,  4.],\n",
      "        [ 9., 16.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[True, True],\n",
      "        [True, True]])\n",
      "tensor([[False, False],\n",
      "        [False, False]])\n",
      "tensor([[  1.,   4.],\n",
      "        [ 27., 256.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([[1, 2], [3, 4]])  # 2x2 크기의 텐서 a를 생성합니다.\n",
    "b = torch.Tensor([[1, 2], [3, 4]])  # 2x2 크기의 텐서 b를 생성합니다.\n",
    "\n",
    "print(a + b)  # 행렬 덧셈: 텐서 a와 b의 요소를 더하여 결과를 출력합니다.\n",
    "print(a - b)  # 행렬 뺄셈: 텐서 a와 b의 요소를 빼서 결과를 출력합니다.\n",
    "print(a * b)  # 요소별 곱셈: 텐서 a와 b의 요소를 곱하여 결과를 출력합니다.\n",
    "print(a / b)  # 요소별 나눗셈: 텐서 a와 b의 요소를 나누어 결과를 출력합니다.\n",
    "print(a == b)  # 요소별 비교 (같음): 텐서 a와 b의 요소가 같은지 비교하여 True 또는 False를 출력합니다.\n",
    "print(a != b)  # 요소별 비교 (다름): 텐서 a와 b의 요소가 다른지 비교하여 True 또는 False를 출력합니다.\n",
    "print(a ** b)  # 요소별 거듭제곱: 텐서 a의 요소를 텐서 b의 요소만큼 제곱하여 결과를 출력합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 3.],\n",
      "        [4., 5.]])\n",
      "tensor([[-2., -1.],\n",
      "        [ 0.,  1.]])\n",
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n",
      "tensor([[0.5000, 1.0000],\n",
      "        [1.5000, 2.0000]])\n",
      "tensor([[0., 1.],\n",
      "        [1., 2.]])\n",
      "tensor([[False,  True],\n",
      "        [False, False]])\n",
      "tensor([[False, False],\n",
      "        [ True,  True]])\n",
      "tensor([[ True, False],\n",
      "        [ True,  True]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\it\\AppData\\Local\\Temp\\ipykernel_3904\\3471457635.py:5: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  print(a//2)  #// 연산자는 파이썬에서 사용되는 정수 나눗셈(나누기 연산의 몫을 계산)을 수행하는 연산자\n"
     ]
    }
   ],
   "source": [
    "print(a+1)\n",
    "print(a-3)\n",
    "print(a*2)\n",
    "print(a/2)\n",
    "print(a//2)  #// 연산자는 파이썬에서 사용되는 정수 나눗셈(나누기 연산의 몫을 계산)을 수행하는 연산자\n",
    "print(a==2)\n",
    "print(a>2)\n",
    "print(a!=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([1, 2])\n",
      "tensor([[2., 4.],\n",
      "        [4., 6.]])\n"
     ]
    }
   ],
   "source": [
    "c=torch.tensor([1,2])\n",
    "print(a)\n",
    "print(c)\n",
    "print(a+c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[ 1.,  4.],\n",
      "        [ 9., 16.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[ 1.,  4.],\n",
      "        [ 9., 16.]])\n",
      "tensor([[ 1.,  4.],\n",
      "        [ 9., 16.]])\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(b)\n",
    "print(a*b) #<- 같은 행 열의 자리의값들끼리 곱함\n",
    "print(a)\n",
    "print(a.mul_(b)) # (= print(a*b)과 같은 기능이지만, a의 값이 변해버림\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  4.],\n",
      "        [ 9., 16.]])\n",
      "tensor(30.)\n",
      "tensor([10., 20.])\n",
      "tensor([ 5., 25.])\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(a.sum())\n",
    "print(a.sum(dim=0)) #열끼리 더하기\n",
    "print(a.sum(dim=1)) #행끼리 더하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2],\n",
      "         [ 3,  4]],\n",
      "\n",
      "        [[ 5,  6],\n",
      "         [ 7,  8]],\n",
      "\n",
      "        [[ 9, 10],\n",
      "         [11, 12]]], dtype=torch.int32)\n",
      "tensor([[15, 18],\n",
      "        [21, 24]])\n",
      "tensor([[ 4,  6],\n",
      "        [12, 14],\n",
      "        [20, 22]])\n",
      "tensor([[ 3,  7],\n",
      "        [11, 15],\n",
      "        [19, 23]])\n",
      "tensor([[ 3,  7],\n",
      "        [11, 15],\n",
      "        [19, 23]])\n"
     ]
    }
   ],
   "source": [
    "t = np.arange(1, 13).reshape(3, 2, 2)  # 1부터 12까지의 숫자를 3x2x2 크기의 다차원 배열로 생성합니다. # (z, y, x축) 순서로 다차원 배열이 구성됩니다.\n",
    "t = torch.from_numpy(t)  # NumPy 배열을 파이토치 텐서로 변환합니다.\n",
    "\n",
    "print(t)  # 3차원 텐서를 출력합니다.\n",
    "print(t.sum(dim=0))  # 첫 번째 축(z 축)을 따라 텐서의 합을 계산합니다.\n",
    "print(t.sum(dim=1))  # 두 번째 축(y 축)을 따라 텐서의 합을 계산합니다.\n",
    "print(t.sum(dim=2))  # 세 번째 축(x 축)을 따라 텐서의 합을 계산합니다.\n",
    "print(t.sum(dim=-1))  # 마지막 축(x 축)을 따라 텐서의 합을 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.,  2.],\n",
      "         [ 3.,  4.]],\n",
      "\n",
      "        [[ 5.,  6.],\n",
      "         [ 7.,  8.]],\n",
      "\n",
      "        [[ 9., 10.],\n",
      "         [11., 12.]]])\n",
      "tensor(6.5000)\n",
      "tensor([[5., 6.],\n",
      "        [7., 8.]])\n",
      "tensor([[ 2.,  3.],\n",
      "        [ 6.,  7.],\n",
      "        [10., 11.]])\n",
      "tensor([[ 1.5000,  3.5000],\n",
      "        [ 5.5000,  7.5000],\n",
      "        [ 9.5000, 11.5000]])\n",
      "tensor([[ 1.5000,  3.5000],\n",
      "        [ 5.5000,  7.5000],\n",
      "        [ 9.5000, 11.5000]])\n"
     ]
    }
   ],
   "source": [
    "t=t.float()\n",
    "print(t)\n",
    "print(t.mean())\n",
    "print(t.mean(dim=0))\n",
    "print(t.mean(dim=1))\n",
    "print(t.mean(dim=2))\n",
    "print(t.mean(dim=-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1],\n",
      "         [ 2,  3],\n",
      "         [ 4,  5]],\n",
      "\n",
      "        [[ 6,  7],\n",
      "         [ 8,  9],\n",
      "         [10, 11]]], dtype=torch.int32)\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]], dtype=torch.int32)\n",
      "tensor([[[ 1,  3],\n",
      "         [ 5,  7],\n",
      "         [ 9, 11]],\n",
      "\n",
      "        [[ 7,  9],\n",
      "         [11, 13],\n",
      "         [15, 17]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(12).reshape(2,3,-1)\n",
    "b = np.arange(2, 14).reshape(2,3,-1)\n",
    "c = np.arange(1,7).reshape(3,2)\n",
    "ta = torch.from_numpy(a)\n",
    "tb = torch.from_numpy(b)\n",
    "tc = torch.from_numpy(c)\n",
    "print(ta)\n",
    "# print(tb)\n",
    "print(tc)\n",
    "print(ta + tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1,13)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12]])\n"
     ]
    }
   ],
   "source": [
    "# print(x.view(3,4))\n",
    "# print(x.view(4,3))\n",
    "# print(x.view(3,2,2))\n",
    "print(x.view(1,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n"
     ]
    }
   ],
   "source": [
    "x1 = x.view(1,3,4)\n",
    "print(x1.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1,  2,  3,  4],\n",
      "          [ 5,  6,  7,  8],\n",
      "          [ 9, 10, 11, 12]]]])\n"
     ]
    }
   ],
   "source": [
    "print(x1.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2],\n",
       "         [ 3,  4],\n",
       "         [ 5,  6]],\n",
       "\n",
       "        [[ 7,  8],\n",
       "         [ 9, 10],\n",
       "         [11, 12]]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = x.view(2,3,2)\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2,  4,  6],\n",
      "        [ 8, 10, 12]])\n"
     ]
    }
   ],
   "source": [
    "print(x2[:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "torch.Size([4, 3])\n",
      "torch.Size([4, 3])\n",
      "torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor(4,10)\n",
    "splits = x.split(3, dim=1)\n",
    "for s in splits:\n",
    "    print(s.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1,  2],\n",
       "          [ 3,  4]],\n",
       "\n",
       "         [[ 5,  6],\n",
       "          [ 7,  8]],\n",
       "\n",
       "         [[ 9, 10],\n",
       "          [11, 12]],\n",
       "\n",
       "         [[13, 14],\n",
       "          [15, 16]]],\n",
       "\n",
       "\n",
       "        [[[17, 18],\n",
       "          [19, 20]],\n",
       "\n",
       "         [[21, 22],\n",
       "          [23, 24]],\n",
       "\n",
       "         [[25, 26],\n",
       "          [27, 28]],\n",
       "\n",
       "         [[29, 30],\n",
       "          [31, 32]]],\n",
       "\n",
       "\n",
       "        [[[33, 34],\n",
       "          [35, 36]],\n",
       "\n",
       "         [[37, 38],\n",
       "          [39, 40]],\n",
       "\n",
       "         [[41, 42],\n",
       "          [43, 44]],\n",
       "\n",
       "         [[45, 46],\n",
       "          [47, 48]]],\n",
       "\n",
       "\n",
       "        [[[49, 50],\n",
       "          [51, 52]],\n",
       "\n",
       "         [[53, 54],\n",
       "          [55, 56]],\n",
       "\n",
       "         [[57, 58],\n",
       "          [59, 60]],\n",
       "\n",
       "         [[61, 62],\n",
       "          [63, 64]]]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1,65).view(4,4,2,2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1],\n",
       "         [ 4],\n",
       "         [ 7]],\n",
       "\n",
       "        [[10],\n",
       "         [13],\n",
       "         [16]],\n",
       "\n",
       "        [[19],\n",
       "         [22],\n",
       "         [25]]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = torch.LongTensor([0])\n",
    "y = x.index_select(dim=2, index = index)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 11, 12]]])\n",
      "tensor([[[11, 12, 13],\n",
      "         [14, 15, 16]],\n",
      "\n",
      "        [[17, 18, 19],\n",
      "         [20, 21, 22]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1, 13).view(2,2,3)\n",
    "y = torch.arange(11,23).view(2,2,3)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3, 11, 12, 13],\n",
       "         [ 4,  5,  6, 14, 15, 16]],\n",
       "\n",
       "        [[ 7,  8,  9, 17, 18, 19],\n",
       "         [10, 11, 12, 20, 21, 22]]])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.cat([x,y], dim=2)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1,  2,  3],\n",
       "          [11, 12, 13]],\n",
       "\n",
       "         [[ 4,  5,  6],\n",
       "          [14, 15, 16]]],\n",
       "\n",
       "\n",
       "        [[[ 7,  8,  9],\n",
       "          [17, 18, 19]],\n",
       "\n",
       "         [[10, 11, 12],\n",
       "          [20, 21, 22]]]])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.stack([x,y], dim=2)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1,  2,  3],\n",
       "          [ 4,  5,  6]],\n",
       "\n",
       "         [[ 7,  8,  9],\n",
       "          [10, 11, 12]]],\n",
       "\n",
       "\n",
       "        [[[ 1,  2,  3],\n",
       "          [ 4,  5,  6]],\n",
       "\n",
       "         [[ 7,  8,  9],\n",
       "          [10, 11, 12]]],\n",
       "\n",
       "\n",
       "        [[[ 1,  2,  3],\n",
       "          [ 4,  5,  6]],\n",
       "\n",
       "         [[ 7,  8,  9],\n",
       "          [10, 11, 12]]]])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(1,2,2,3)\n",
    "y = x.expand(3,2,2,3)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3]],\n",
      "\n",
      "        [[4, 5, 6]]])\n",
      "tensor([[[1, 2, 3],\n",
      "         [1, 2, 3]],\n",
      "\n",
      "        [[4, 5, 6],\n",
      "         [4, 5, 6]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1, 7).view(2,1,3)\n",
    "y = x.expand(2,2,3)\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([75, 99, 82,  7, 67, 11, 62, 90, 24, 38, 53, 52,  1, 27, 63, 96, 22, 12,\n",
       "        46, 97, 87, 84, 88, 68, 66, 23, 28, 72,  8, 29, 70, 35, 25, 26, 45, 54,\n",
       "        58, 16, 19, 41, 10, 81, 61, 71, 69,  0, 91, 86, 48, 74, 34, 55, 43, 44,\n",
       "        92, 33,  4,  2, 31, 21, 95, 20, 98, 65, 80, 56, 64, 89, 60, 83, 36, 40,\n",
       "        76, 13,  9, 73, 14,  6,  5, 94,  3, 32, 39, 59, 57, 47, 51, 15, 30, 78,\n",
       "        85, 18, 50, 37, 93, 49, 17, 42, 79, 77])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randperm(100)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 8,  9, 12],\n",
       "         [25,  4, 11],\n",
       "         [13,  1,  6]],\n",
       "\n",
       "        [[20,  3, 15],\n",
       "         [19, 23, 18],\n",
       "         [26, 17, 22]],\n",
       "\n",
       "        [[24, 10, 21],\n",
       "         [ 0, 16,  2],\n",
       "         [ 7, 14,  5]]])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randperm(3**3).view(3,3,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 1]])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.argmax(dim=2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[25,  9, 12]],\n",
      "\n",
      "        [[26, 23, 22]],\n",
      "\n",
      "        [[24, 16, 21]]])\n",
      "tensor([[[1, 0, 0]],\n",
      "\n",
      "        [[2, 1, 2]],\n",
      "\n",
      "        [[0, 1, 0]]])\n"
     ]
    }
   ],
   "source": [
    "value, indices = torch.topk(x, k=1, dim=1)\n",
    "print(value)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 4, 1],\n",
       "        [6, 0, 5],\n",
       "        [3, 7, 8]])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randperm(9).view(3,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False,  True],\n",
       "        [False,  True, False],\n",
       "        [ True, False, False]])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = x < 4\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 4, 0],\n",
       "        [6, 0, 5],\n",
       "        [0, 7, 8]])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.masked_fill(mask, value=0)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
