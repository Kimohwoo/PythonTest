{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1cffde56af0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = torch.FloatTensor([[1],[2],[3],[4],[5]])\n",
    "t_data = torch.FloatTensor([[3],[5],[7],[9],[11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.], requires_grad=True) tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "w = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "print(w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x_data*w+b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(57., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "cost = torch.mean((t_data - y)**2)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize = optim.SGD([w,b], lr = 0.01) #경사하강법으로 w,b 업데이트 하기위한 최적화식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0 w: 1.173, b: 0.329 Cost: 19.377302\n",
      "Epoch  100 w: 2.081, b: 0.708 Cost: 0.015653\n",
      "Epoch  200 w: 2.058, b: 0.792 Cost: 0.007951\n",
      "Epoch  300 w: 2.041, b: 0.852 Cost: 0.004039\n",
      "Epoch  400 w: 2.029, b: 0.894 Cost: 0.002052\n",
      "Epoch  500 w: 2.021, b: 0.925 Cost: 0.001042\n",
      "Epoch  600 w: 2.015, b: 0.946 Cost: 0.000529\n",
      "Epoch  700 w: 2.011, b: 0.962 Cost: 0.000269\n",
      "Epoch  800 w: 2.008, b: 0.973 Cost: 0.000137\n",
      "Epoch  900 w: 2.005, b: 0.981 Cost: 0.000069\n",
      "Epoch 1000 w: 2.004, b: 0.986 Cost: 0.000035\n",
      "Epoch 1100 w: 2.003, b: 0.990 Cost: 0.000018\n",
      "Epoch 1200 w: 2.002, b: 0.993 Cost: 0.000009\n",
      "Epoch 1300 w: 2.001, b: 0.995 Cost: 0.000005\n",
      "Epoch 1400 w: 2.001, b: 0.996 Cost: 0.000002\n",
      "Epoch 1500 w: 2.001, b: 0.997 Cost: 0.000001\n",
      "Epoch 1600 w: 2.001, b: 0.998 Cost: 0.000001\n",
      "Epoch 1700 w: 2.000, b: 0.999 Cost: 0.000000\n",
      "Epoch 1800 w: 2.000, b: 0.999 Cost: 0.000000\n",
      "Epoch 1900 w: 2.000, b: 0.999 Cost: 0.000000\n",
      "Epoch 2000 w: 2.000, b: 1.000 Cost: 0.000000\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 2000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    y = x_data*w + b\n",
    "    cost = torch.mean((y-t_data)**2)\n",
    "\n",
    "    optimize.zero_grad()\n",
    "    cost.backward()\n",
    "    optimize.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d} w: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(epoch, w.item(), b.item(), cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/2000, Hypothesis:tensor([0., 0., 0., 0., 0.]) b: 0.000 Cost: 29661.800781\n",
      "Epoch  100/2000, Hypothesis:tensor([0.0342, 0.0342, 0.0342, 0.0342, 0.0342]) b: 0.035 Cost: 29650.105469\n",
      "Epoch  200/2000, Hypothesis:tensor([0.0684, 0.0684, 0.0684, 0.0684, 0.0684]) b: 0.069 Cost: 29638.416016\n",
      "Epoch  300/2000, Hypothesis:tensor([0.1026, 0.1026, 0.1026, 0.1026, 0.1026]) b: 0.103 Cost: 29626.730469\n",
      "Epoch  400/2000, Hypothesis:tensor([0.1367, 0.1367, 0.1367, 0.1367, 0.1367]) b: 0.137 Cost: 29615.050781\n",
      "Epoch  500/2000, Hypothesis:tensor([0.1709, 0.1709, 0.1709, 0.1709, 0.1709]) b: 0.171 Cost: 29603.378906\n",
      "Epoch  600/2000, Hypothesis:tensor([0.2051, 0.2051, 0.2051, 0.2051, 0.2051]) b: 0.205 Cost: 29591.707031\n",
      "Epoch  700/2000, Hypothesis:tensor([0.2392, 0.2392, 0.2392, 0.2392, 0.2392]) b: 0.240 Cost: 29580.042969\n",
      "Epoch  800/2000, Hypothesis:tensor([0.2734, 0.2734, 0.2734, 0.2734, 0.2734]) b: 0.274 Cost: 29568.378906\n",
      "Epoch  900/2000, Hypothesis:tensor([0.3075, 0.3075, 0.3075, 0.3075, 0.3075]) b: 0.308 Cost: 29556.718750\n",
      "Epoch 1000/2000, Hypothesis:tensor([0.3417, 0.3417, 0.3417, 0.3417, 0.3417]) b: 0.342 Cost: 29545.068359\n",
      "Epoch 1100/2000, Hypothesis:tensor([0.3758, 0.3758, 0.3758, 0.3758, 0.3758]) b: 0.376 Cost: 29533.417969\n",
      "Epoch 1200/2000, Hypothesis:tensor([0.4099, 0.4099, 0.4099, 0.4099, 0.4099]) b: 0.410 Cost: 29521.781250\n",
      "Epoch 1300/2000, Hypothesis:tensor([0.4440, 0.4440, 0.4440, 0.4440, 0.4440]) b: 0.444 Cost: 29510.144531\n",
      "Epoch 1400/2000, Hypothesis:tensor([0.4781, 0.4781, 0.4781, 0.4781, 0.4781]) b: 0.478 Cost: 29498.505859\n",
      "Epoch 1500/2000, Hypothesis:tensor([0.5122, 0.5122, 0.5122, 0.5122, 0.5122]) b: 0.513 Cost: 29486.878906\n",
      "Epoch 1600/2000, Hypothesis:tensor([0.5463, 0.5463, 0.5463, 0.5463, 0.5463]) b: 0.547 Cost: 29475.255859\n",
      "Epoch 1700/2000, Hypothesis:tensor([0.5804, 0.5804, 0.5804, 0.5804, 0.5804]) b: 0.581 Cost: 29463.634766\n",
      "Epoch 1800/2000, Hypothesis:tensor([0.6145, 0.6145, 0.6145, 0.6145, 0.6145]) b: 0.615 Cost: 29452.025391\n",
      "Epoch 1900/2000, Hypothesis:tensor([0.6486, 0.6486, 0.6486, 0.6486, 0.6486]) b: 0.649 Cost: 29440.406250\n",
      "Epoch 2000/2000, Hypothesis:tensor([0.6826, 0.6826, 0.6826, 0.6826, 0.6826]) b: 0.683 Cost: 29428.806641\n"
     ]
    }
   ],
   "source": [
    "x_data = torch.FloatTensor([[73., 80., 75.],\n",
    "                            [93., 88., 93.],\n",
    "                            [89., 91., 90.],\n",
    "                            [96., 98., 100.],\n",
    "                            [73., 66., 70.]])\n",
    "t_data = torch.FloatTensor([[152.],\n",
    "                            [185.],\n",
    "                            [180.],\n",
    "                            [196.],\n",
    "                            [142.]])\n",
    "\n",
    "W = torch.zeros((3,1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# y = x_data.matmul(W) + b\n",
    "optimizer = optim.SGD([w,b], lr=1e-6)\n",
    "nb_epochs = 2000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    y = x_data.matmul(W) + b\n",
    "    cost = torch.mean((y-t_data)**2)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{}, Hypothesis:{} b: {:.3f} Cost: {:.6f}'.format(epoch, nb_epochs, y.squeeze().detach(), b.item(), cost.item()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
